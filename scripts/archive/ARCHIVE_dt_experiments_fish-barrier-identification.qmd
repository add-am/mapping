---
title: "Dry Tropics Spatial Analysis (Experiment: Fish Barrier Identification)"
author: "Adam Shand"
date: "`r format(Sys.time(), '%d, %B, %Y')`"
format: html
params:
  project_crs: "EPSG:7844"
execute: 
  warning: false
---

::: {.callout-tip}
## R Version
For R session info at the time of rendering this script see @sec-sessioninfo.
:::

# Introduction

This script is an experimentation of automated identification of fish barriers using a variety of tools and datasets. Each method builds upon the last. The method is inspired by the 2008 Burdekin Barriers study conducted by Alluvium on behalf of NQDT (methods doc in the additional resources folder). Some adjustments have been made however the main prioritization criteria is the same. Note that the prioritization criteria that are listed and not used are also not used by the Alluvium study.

Barriers are identified as follows:

- By downloading three watercourse barrier datasets:
    + dams_weirs_barrages
    + major_dam_walls
    + minor_dam_walls
- By intersecting all known watercourses with all known roads and rails

Barriers are prioritized using the follow criteria (importance = how important the removal of remediation of the barrier is)

- Stream order, streams with a greater stream order are of greater importance
    + A sub section of this, streams with an order of 1 are not considered within the study due to their abundance and small size
- Stream order x Road type
    + Intersections between roads of type "highway" and streams of order >4 are not considered as the intersections are almost certainly elevated bridges.
- Distance to next barrier upstream, barriers with no barriers or barriers much further upstream are of greater importance
- Presence/Absence of downstream barriers, a barrier with no additional barriers further downstream is of greater importance
- Position of Barrier in the Catchment, barriers with a high proportion of the catchment upstream are of greater importance
- Uninterrupted stream length upstream, barriers with lots of total area upstream are of greater importance

Barriers are NOT prioritized (but it would be good if they were) by the following criteria:

- Upstream habitat quantity (Perennial water in Ha)
- Upstream habitat quantity (Ephemeral water in Ha)
- Upstream habitat quality (such as that of riparian health)
- Proximity to downstream aquatic refuge

# Script Set Up

This script requires multiple core spatial packages, a custom function has been written to handle package installation and loading.

```{r}
#| label: load packages
#| output: false

#read in the custom function (note that we have to use "../" to step one folder out. (cant use "here()" as it might not be installed).
source("../functions/package_handling.R")

#run the package handling function, read the function for details
package_handling(c("sf", "tmap", "glue", "here", "tidyverse", "terra", "rayshader", "igraph", "riverdist"))

```

Then we also need to set up key variables for the script, as well as the output location.

```{r}
#| label: create save path and establish project crs

#set project crs
proj_crs <- params$project_crs

#create a file path to help with saving outputs
save_path <- here("outputs/dt_experiments_fish-barrier-identification/")
data_path <- here("data/dt_experiments/fish_barriers_data/")

#bring the path to life
dir.create(save_path)
dir.create(data_path)

#turn off s2 geometry
sf_use_s2(FALSE)
tmap_mode("plot")

```

# Load Data

We can now load in all of the datasets that we will be using. This can be broken down in three main categories. 

- The General northern three region data and northern three watercourses data
- Pre-existing barrier datasets
- Datasets to calculate additional barriers
  + N3 region watercourses,
  + Roads and rails

## Basic Data

First we will load in the most basic data that we always use. This data is the n3_region dataset and associated watercourses, and an outline of Queensland that we use for the background of our maps.

::: {.callout-note}
For the purpose of this script, we will be experimenting exclusively in the Black River and Bluewater Creek sub basins, with the eventual intention of expanding the methodology to the entire n3 region.
:::

```{r}
#| label: read in basic data

#read in the n3_region dataset
n3_region <- st_read(here("data/n3_prep_region-builder/n3_region.gpkg"))

#cut down to a test location, in this case we will pick black river and bluewater
test_location <- n3_region |> 
  filter(sub_basin_or_sub_zone %in% c("Black River", "Bluewater Creek")) |> 
  st_transform(proj_crs)

#read in the n3_watercourse data
n3_watercourse <- st_read(here("data/n3_prep_watercourse-builder/n3_watercourse.gpkg"))

#cutdown to a test location, in this case we will pick black river and bluewater, and exclusively the freshwater environment
test_location_watercourse <- n3_watercourse |> 
  filter(sub_basin_or_sub_zone %in% c("Black River", "Bluewater Creek"),
         environment == "Freshwater") |> 
  select(-environment) |> 
  st_transform(proj_crs)

#read in qld outlines data from the gisaimsr package, filter for land and islands, update crs
qld <- get(data("gbr_feat", package = "gisaimsr")) |> filter(FEAT_NAME %in% c("Mainland", "Island")) |> 
  st_transform(proj_crs)

```

### Refine The Basic Data

Before looking at the watercourse barriers we need to refine the watercourses which we care about. The first step of this is to remove streams with a strahler stream order of 1 as these are deemed to be low priority and/or unlikely to be a barrier.

```{r}
#| label: intersect the road and watercourse data

#filter for specific watercourses then drop stream order and source as it is no longer needed
filtered_test_location_watercourse <- test_location_watercourse |> 
  filter(stream_order %in% c(2:15)) |> 
  select(-source)

```

While the second step is to assign a unique ID to every watercourse so we know exactly where each barrier is.

### Assign Unique ID

As detailed in [Issue #92](https://github.com/Northern-3/spatial-analyses/issues/92) we require every single watercourse to receive a unique ID. This may seem to be covered by the sub_basin column, but we are actually looking to classify each distinct watercourse, i.e. a sub basin could encompasses several watercourse. that never technically meet - making them unique, and needing a unique ID to track barriers specific to that watercourse.

```{r}
#| label: assign unique watercourse IDs

#run st_intersects for every geometry in the watercourse dataset. This creates a relationship between every geometry that says which other geometry it is connected to
unique_watercourse_id <- st_intersects(filtered_test_location_watercourse)

#we then make a connection graph
connection_graph <- graph_from_adj_list(unique_watercourse_id)

#and extract the membership component (essentially which group of connections does each geometry belong to)
watercourse_memberships <- components(connection_graph)$membership

#this membership component becomes the unique ID assigned to each distinct watercourse
filtered_test_location_watercourse$unique_river_id <- watercourse_memberships

#we then need to calculate the length of every geometry individually, before then calculating the total length of each unique watercourse, making sure to separate by sub basin for those that cross boundaries
filtered_test_location_watercourse <- filtered_test_location_watercourse |> 
  mutate(length = st_length(geom)) |> 
  group_by(sub_basin_or_sub_zone, unique_river_id) |>
  mutate(length = sum(length)) |> 
  ungroup()

#there are a few examples where a watercourse with a unique ID crosses into another sub basin. In this case
#we take the longer of the two watercourses with the same unique ID. To create truly, 100% unique IDs.
unique_watercourse <- filtered_test_location_watercourse |> 
  group_by(unique_river_id) |> 
  filter(length == max(length)) |> 
  ungroup()

#clean up
rm(unique_watercourse_id, watercourse_memberships, connection_graph, filtered_test_location_watercourse)

```

## Pre-Existing Barrier Datasets

We can then load in the three datasets that cover all of the main dams and weirs in the area. As annoying as it may seem, we do actually need all three to correctly identify all of the barriers...

```{r}
#| label: load in pre-existing barrier datasets
#| output: FALSE

#load in each of the three datasets
dams_weirs_barrages <- st_read(glue("{data_path}/dams_weirs_and_barrages.gpkg"))
major_dam_walls <- st_read(glue("{data_path}/major_dam_walls.gpkg"))
minor_dam_walls <- st_read(glue("{data_path}/minor_dam_walls.gpkg"))

```

### Refining Pre-Existing Barrier Data

Then we refine this data specifically to our focus location. However, instead of making sure that each barrier inherits the features of the location we will just do a boolean in/out, and instead allow barriers to inherit features based on proximity to our refined watercourse dataset.

The in/out boolean is achieved by simply using st_union on the test_location file. This will assign features such as region, basin, and sub basin to each of the pre-existing barriers.

::: {.callout-note}
For the duration of the experimentation phase the dams weirs and barrages, and major dam datasets will be empty, but when doing the full analysis they will contain data.
:::

```{r}
#| label: intersect pre-existing data

#intersect each of the pre-existing barrier datasets with our target location to obtain location specific information
location_dwb <- st_intersection(dams_weirs_barrages, st_union(test_location))
location_major_dam <- st_intersection(major_dam_walls, st_union(test_location))
location_minor_dam <- st_intersection(minor_dam_walls, st_union(test_location))

#select columns we are interested in and rename to be consistent
location_dwb <- location_dwb |> 
  select(infrastructure) |> 
  rename(construct = infrastructure)

location_major_dam <- location_major_dam |> 
  select(dam_type) |> 
  rename(construct = dam_type)

location_minor_dam <- location_minor_dam |> 
  select(feature_type) |> 
  rename(construct = feature_type)

#join the preexisting data
pre_existing_points <- rbind(location_dwb, location_major_dam, location_minor_dam)

#get center points as some of the data is provided as a polygon
pre_existing_points <- st_centroid(pre_existing_points)

#clean up
rm(dams_weirs_barrages, major_dam_walls, minor_dam_walls, location_dwb, location_major_dam, location_minor_dam)

```

### Repositioning Pre-Existing Barriers

After refining the barriers to just the n3 region we need to refine the barriers to watercourses that we care about. As noted in [issue 94](https://github.com/Northern-3/spatial-analyses/issues/94) these pre-existing barriers don't indicate which watercourse they are on (relative to our n3 watercourse dataset), nor do they indicate if the are even on a watercourse that we are looking at. 

We will kill three birds with one stone by doing the following actions:

- determine if the barrier is with 100m of one of our watercourses
- determine, if so, which watercourse the barrier is closest too
- move the barrier to intersect perfectly with the watercourse, and inherit its features.

#### Summarise Watercourses

First we need to summarise the waterways into a single geometry per unique ID. Otherwise the distance comparison will look at every single row of geometries. It is important to note that by summarizing the water here we lose the stream_order variable which is important later, so we will make a temporary copy for the summary. We will also assign a completely unique tracker to each of the barriers we are looking at.

```{r}
#| label: summarise watercourse

#very row  needs a unique identifier outside of its length
pre_existing_points <- pre_existing_points |> 
  mutate(special_id = row_number(pre_existing_points))

#summarise water
unique_watercourse_summarised <- unique_watercourse |> 
  group_by(region, basin_or_zone, sub_basin_or_sub_zone, unique_river_id, length) |> 
  summarise()

```

#### Find the Nearest Watercourse

Then we run the nearest points function, which creates linestring geometries. The line start at the barrier, and goes to the closest part of the watercourse. It does this from the barrier to every single one of the watercourse geometries (hence why we had to summarise the dataset above). So in total we have x number of barriers times y number of watercourses worth of lines. Which is: `r nrow(snap_to_points)` x `r nrow(unique_watercourse_summarised)` = `r nrow(snap_to_points)*nrow(unique_watercourse_summarised)`.

```{r}
#| label: draw lines to watercourse

#we then run the nearest points function
lines_from_point_to_watercourse <- st_sf(geom = st_nearest_points(pre_existing_points, 
                                                                  unique_watercourse_summarised), crs = proj_crs)

```

After this is done we need to add back on the special IDs. As noted above, we know that there will be `r nrow(snap_to_points)*nrow(unique_watercourse_summarised)` rows of data. So to correctly add the special ID we need to repeat the `r unique(snap_to_points$special_id)` unique IDs a total of `r nrow(unique_watercourse_summarised)` times. 

Here we will also add back the information about the type of barrier that the point represents.

```{r}
#| label: add extra information

#add each of the vectors
nearest_points <- lines_from_point_to_watercourse |> 
  mutate(special_id = rep(pre_existing_points$special_id, 
                          each = nrow(unique_watercourse_summarised)),
         construct = rep(pre_existing_points$construct,
                         each = nrow(unique_watercourse_summarised)))
```

Once the ID column is added, we calculate the length of every single line, then group by the ID and select line with the shortest length. The line with the shortest length is the line that points from the barrier to the closest watercourse. The start coords of this line will be the coords of the barrier, and the end coords of this line will the coords of the closest point on the closest watercourse that we can snap the line to.

```{r}
#| lable: find shortest line

#we can then measure the length of each line casted, group by the variables we just added, and pick the line with the shortest length
nearest_points <- nearest_points |> 
  mutate(length = st_length(geom)) |> 
  group_by(across(-c(geom, length))) |> 
  filter(length == min(length)) |> 
  ungroup()

```

Once this is do we can also use this opportunity to check if the barrier is even within a 100m of the closest watercourse. We have decided that those that are not within 100m are too far away to be of consideration. A simple true/false column will be used to extract the rows of interest

```{r}
#| label: check proximity to watercourse

#check if length is equal to or less than 100 (i.e. if barrier is within 100m of watercourse)
nearest_points <- nearest_points |> 
  mutate(in_proximity = case_when(length > units::set_units(100, "m") ~ FALSE,
                                  T ~ TRUE))

#select only rows that are TRUE for in proximity and clean up the dataset by removing unnecessary columns
nearest_points <- nearest_points |> 
  filter(in_proximity) |> 
  select(special_id, construct)

```

#### Snap Barriers to Watercourse

Following this, we then convert the lines to points. For each row, the line string contains 4 coordinates, a pair of coordinates for the start of the line, and a pair for the end. The first pair is always the origin, thus the second pair is on the watercourse. We convert the data from line to point, and then select every second row (i.e. every second pair).

```{r}
#| label: convert lines to points

#then we can extract the second pair of geometries from the line strings to find the end points of each line. which will be the closest point on the waterbody to the line
nearest_points <- st_cast(nearest_points, "POINT")

#simply sequence by 2 up to the length of the table
snap_to_points <- nearest_points[seq(2, nrow(nearest_points), by = 2),]

```

To recap, we now have a dataset that connects to the original barriers dataset through the "special_ID" column. This new dataset contains the coordinates that the original barriers should be snapped to so that they land perfectly on our watercourse lines dataset. This new dataset has also been filtered to only contains barriers that should be snapped. 

However... neither the new dataset or the old dataset have inherited the information of the watercourse that the barrier has been snapped too. Information such as the name of the watercourse, the sub basin it is in, the basin, zone, etc.

To obtain this information we can use a very similar function to above, the `st_nearest_feature()` function. Which, for each row, provides the index of the closest feature in the other dataset. It is important to note here that the second dataset in this function will be the un-summarised watercourse dataset, because we still need the stream order information.

```{r}
#| label: find nearest feature

#find the nearest feature
snap_to_points$nearest_feature <- st_nearest_feature(snap_to_points, unique_watercourse)

```

We can then use the row index to perform a left join, which allows each point to inherit the information of the closest watercourse.

```{r}
#| label: join by row index

#pull out the row index in the watercourse dataset for its own col
unique_watercourse <- unique_watercourse |> 
  mutate(row_index = row_number())

#join the datasets by adding the unique watercourse information to the preexisting barriers based on the row index (which ever feature was the closest)
snap_to_points <- left_join(snap_to_points, 
                            st_drop_geometry(unique_watercourse), 
                            by = c("nearest_feature" = "row_index"))

#edit the data to keep just what we need
snap_to_points <- snap_to_points |> 
  select(-c(geographic_area, stream_order, special_id, nearest_feature))

#clean up
rm(unique_watercourse_summarised, lines_from_point_to_watercourse, nearest_points)

```

To confirm, that everything worked we will do a quick visual. Red = snapped points, Blue = original points.

```{r}
#| label: visualise to confirm

tmap_mode("view")

tm_shape(unique_watercourse) +
  tm_lines() +
  tm_shape(snap_to_points) +
  tm_dots(col = "red") +
  tm_shape(pre_existing_points) +
  tm_dots(col = "blue")

```

```{r}
#| label: turn off interactive viewing

tmap_mode("plot")

rm(pre_existing_points)

```

The pre-existing barriers can now be put on hold while we deal with identifying new barriers.

## New Barriers Dataset

Below we load in the roads and rails for the entirety of Queensland.

```{r}
#| label: read in the additional data needed for extra barriers

#read in road and rail
road <- st_read(glue("{data_path}/queensland_roads_and_tracks.gpkg"))
rail <- st_read(glue("{data_path}/rail_network.gpkg"))

```

### Refining New Barriers Data

If we were to intersect every single watercourse in the testing region, with every single road, we would have `r nrow(st_intersection(road, test_location_watercourse))` different points of interest to inspect. Which might not seem like alot, but considering this is just one tiny area of the N3 region, does not bode well.

So we have to look at methods of eliminating some of the POIs before they even become a POI. As detailed in [Issue #90](https://github.com/Northern-3/spatial-analyses/issues/90) we can eliminate instances of highway x stream order >4, and all streams of order 1 as these are deemed to be low priority and/or unlikely to be a barrier. The streams of strahler order 1 has already been done when refining the basic data, and to find the highway x stream order >4 POIs we can use the intersection function.

#### Intersect Transport and Watercourse

We can intersect our data to find the highway x stream order >4 combinations and remove them. This is very straight forward, simply intersecting the data and discarding points that have both of the features.

We can also apply this same logic to railway x stream order >4 combinations (next code chunk).

```{r}
#| label: intersect the road and watercourse data

#intersect road and watercourse and remove instances of highway x stream order >4
road_points <- st_intersection(unique_watercourse, road) |> 
  filter(road_type != "Highway" | (road_type == "Highway" & stream_order < 5))

#clean up
rm(test_location_watercourse)

```

This leaves us with `r nrow(road_point)` POIs, which is much better to work with. However, we still do need to add in the rail network.

```{r}
#| label: do the same for rail

#intersect rail and watercourse
rail_points <- st_intersection(unique_watercourse, rail) |> 
  filter(stream_order < 5)

```

Which brings the total up to `r nrow(road_points) + nrow(rail_points)`.

#### Combine Intersections

We can then combine the road and rail intersections, only keeping the relevant information.

```{r}
#| label: edit data for combining

#edit
road_points <- road_points |> 
  select(region, basin_or_zone, sub_basin_or_sub_zone, unique_river_id, length, road_type) |> 
  rename(construct = road_type)

#edit
rail_points <- rail_points |> 
  select(region, basin_or_zone, sub_basin_or_sub_zone, unique_river_id, length, feature_type) |> 
  rename(construct = feature_type)

#bind data
intersection_points <- rbind(rail_points, road_points)

#clean up datasets
rm(road, road_points, rail, rail_points)

```

For some reason some of the points also come in the multipoint geometry type (i.e. contains 2 or more points within one geometry), which can be a bit confusing when looking at the data, so we will quickly take care of that.

To demonstrate the issue. The number of rows of data we have before is : `r nrow(intersection_points)`

```{r}
#| label: remove multipoint type

#first make everything a multipoint type
intersection_points <- st_cast(intersection_points, "MULTIPOINT")

#then make everything a point type.
intersection_points <- st_cast(intersection_points, "POINT")

```

And the number of rows of data we have after is : `r nrow(intersection_points)`

# Combine All Barrier Datasets

Each of the datasets we have created and edited can now be combined into one large (potential) barriers dataset.

```{r}
#| label: combine prexisting and new data

#bind all points
all_points <- rbind(intersection_points, snap_to_points)

#clean up
rm(intersection_points, snap_to_points)

```

However this combination will certainly introduce overlaps. To address overlaps we will:

- create a list that details every point that is within 50m of another point (list by index)
- convert the list into a matrix, and then a vector
- select unique values from this vector - which provides a set of index numbers to remove from the main dataset.

This will reduce the number of points from: `r nrow(all_points)`

```{r}
#| label: remove overlapping points

#update crs to a meter friendly version
all_points <- st_transform(all_points, "EPSG:7855")

#create a list of points that are within 50 of one another
within_50m <- st_is_within_distance(all_points, dist = 100, sparse = T)

#get the second to 9th elements of each vector in the list the 1st element is itself (always within 50m of itself), the 2nd to nth 
#elements are other points within 50. We assume it is unlikely to be more than 4 overlaps, so 9 will certainly catch anything.
within_50m <- map(within_50m, function(x) x[2:10])

#convert this list of lists to a matrix then covert the matrix to a vector and look for every unique value
to_remove <- do.call(rbind, within_50m) |> 
  as.vector() |> unique()

#remove NA values (so we can filter by index)
to_remove <- to_remove[!is.na(to_remove)]
  
#filter rows by index
all_points_no_overlaps <- all_points[-to_remove,]

#clean up
rm(all_points, within_50m, to_remove)

```

to: `r nrow(all_points_no_overlaps)`.

# Prioritising Barriers

We now have the coordinates of all preexisting, and potential barriers. Their coordinates have been perfectly intersected with our watercourse dataset, and we have remove all overlaps and any low priority barriers. The next step is to creating a ranking system that prioritizes barriers for remediation, barriers with a high prioritisation score would have the best improvement to the environment if they were remediated. Through exploration of the available datasets and methods we have determined that barriers can be prioritized based on: 

- Stream order, streams with a greater stream order are of greater importance
    + A sub section of this, streams with an order of 1 are not considered within the study due to their abundance and small size
- Stream order x Road type
    + Intersections between roads of type "highway" and streams of order >4 are not considered as the intersections are almost certainly elevated bridges.
- Distance to next barrier upstream, barriers with no barriers or barriers much further upstream are of greater importance
- Presence/Absence of downstream barriers, a barrier with no additional barriers further downstream is of greater importance
- Position of Barrier in the Catchment, barriers with a high proportion of the catchment upstream are of greater importance
- Uninterrupted stream length upstream, barriers with lots of total area upstream are of greater importance

### Save and Reload Data

As noted above, stream order and road type have already been addressed, thus below we focus on the last four points. These four points can all be achieved using the Riverdist package, however the package requires that we save all data so that we can read it back in using the package-specific functions. The package also requires that all data have a projected (meters) coordinate reference system, so that distance measurements can be completed.

::: {.callout-note}
Further, as flagged in [issue 93](https://github.com/Northern-3/spatial-analyses/issues/93) this method is currently only working on a single outlet basis (i.e. the dataset collectively should only have 1 outlet). We will look into expanding the viable area.
:::

First we will save and reload the watercourse dataset.

```{r}
#| label: save and load watercourses

#summarise the watercourse dataset and create a super simple test case.
test_case <- unique_watercourse |> 
  group_by(region, basin_or_zone, sub_basin_or_sub_zone, unique_river_id) |> 
  summarise(geom = st_union(geom)) |> 
  filter(unique_river_id == 1)

#save the test case
st_write(test_case, glue("{data_path}/watercourse_lines_summarised.shp"), delete_dsn = T)

#read the test case back in (here is where we will change the crs)
test_lines <- line2network(path = data_path, layer = "watercourse_lines_summarised", reproject = "EPSG:7855")

#clean up
rm(test_case)

```

However before we can save and reload our barriers dataset we need to clean up our river network. This is because the river network is required to reload our barriers dataset. This clean up is unfortunately currently a manual process that requires user interaction. Actions include y/n dissolves, y/n segment removes, identification of river mouths etc. To make matters worse, the interactive process is thrown off by the Quarto interactive code chunks and the user cannot effectively view the maps/plots that are meant to help the user answer each question.

::: {.callout-tip}
To assist the user the following code chunk should be run in the console, this will move the plot/graph outputs to the plot panel on the right of RStudio, rather than within the script.
:::

::: {.callout-tip}
Further assistance for this chunk comes in the form of saving the output as the .RData type. This saves the object exactly as it looks in the global environment. Once the manual edit has been done once we can then load it back in each time without having to redo the manual edits.
:::

```{r}
#| label: run cleanup function

if (!file.exists(glue("{data_path}/edited_river_network.RData"))){#if the file doesn't exist
  
  warning("The edited river network file does not exists. To create this network file you must run the following function: 'test_lines_clean <- cleanup(test_lines)'. This function requires several manual imputs and is best run from the console rather than from the Quarto script.\n\n")
  
  stop("Once the river network file has been created it must be saved. Use the function 'save(test_lines_clean, file = glue({m2_saving}/edited_river_network.RData)'.")
  
  #run the clean up function. NOTE - FOR EASE OF USE RUN THIS IN THE CONSOLE
  #test_lines_clean <- cleanup(test_lines)
  
  #save the output
  #save(test_lines_clean, file = glue("{data_path}/edited_river_network.RData"))
  
} else {#if the file does exist

  #load it back in
  load(glue("{data_path}/edited_river_network.RData"))
  
}

#clean up
rm(test_lines)

```

Once the river network has been loaded in and cleaned, we can use it to load in the barriers data.

```{r}
#| label: save and load barriers

#update the crs for the point data, filter for data in our test case area, and add a unique row id for tracking later
all_points_transformed <- all_points_no_overlaps |> 
  st_transform("EPSG:7855") |> 
  filter(unique_river_id == 1) |> 
  mutate(row_id = row_number())

#save the test case to the method 2 folder
st_write(all_points_transformed, glue("{data_path}/barrier_points.shp"), delete_dsn = T)

#read the test case back in, this requires the river network to already be completed and cleaned up
test_points <- pointshp2segvert(path = data_path, layer = "barrier_points", rivers = test_lines_clean)

#rename some variables to help with readability later on
test_points <- test_points |> 
  rename(barrier_segment = seg,
         barrier_vertex = vert)

##select key columns and add them to our original dataset
test_points_select <- test_points |> 
  select(barrier_segment, barrier_vertex, row_id)

all_points_transformed <- left_join(all_points_transformed, test_points_select)

#clean up
rm(all_points_no_overlaps)

```

## Distance to next barrier upstream

The barrier data has been loaded in with a segment and vertex associated with each barrier, which is the segment and vertex of the river network that the barrier is on. We can measure the distances between each of the barriers by feeding in these segments and vertices. This will produce a matrix of each barrier compared to every other barrier. An important variable in this function is the "stopiferror" variable, although counter intuitive we want to set this to false - the reason being that an error occurs if there is no connection between the two barriers (on separate watercourses). Instead we want these to be recorded as NA. 

```{r}
#| label: measure distances

#measure distances between each barrier
distance_between_barriers <- riverdistancemat(seg = test_points$barrier_segment, 
                                              vert = test_points$barrier_vertex, 
                                              rivers = test_lines_clean,
                                              stopiferror = F)

```

The resulting matrix will look like this:

`r head(distance_between_barriers, c(5,5))`

Note that the diagonal entries of zero are the distance from the barrier to itself. Also note that this splits a perfect mirror of the data, i.e. the distance from barrier 1 to barrier 2 is obviously the same as the distance from barrier 2 to barrier 1. This will become important later.

It is also important to note here that for any pair [i,j], the i and j values (row/column vals) correspond to the row id in the barriers dataset. I.e. for [1,2], this corresponds to the first row of the barriers dataset measured against the 2nd row of the barriers dataset. This DOES NOT correspond to the barrier segment. To make that even more clear, for the first row of the barriers dataset, the barrier segment is actually 53.

Below we convert this matrix to a table and rename columns to help understand distances between A and B.

```{r}
#| label: convert to table

# Convert matrix to dataframe
distance_to_closest_barrier <- as.data.frame.table(distance_between_barriers, responseName = "distance_to_barrier")

# Rename columns
names(distance_to_closest_barrier) <- c("barrier_a_id", "barrier_b_id", "distance_to_barrier")

```

This gives us a table to cross check:

`r head(distance_to_closest_barrier)`

From this, we can remove all instances where the barrier is checked against itself, i.e. cases in which the unique row id for barrier a is equal to the unique row id for barrier b.

This reduces the number of pairs to check from `r nrow(barrier_proximity)`,

```{r}
#| label: filter pairs table

#filter data
distance_to_closest_barrier <- distance_to_closest_barrier |> 
  filter(barrier_a_id != barrier_b_id)

```

to `r nrow(distance_to_closest_barrier)`.

We can then directly connect the barrier_a_id x barrier_b_id pairs back to the original barrier dataset we loaded in via the id columns. For example, the barrier_a_id x barrier_b_id pair: 2 x 4, is saying that the barrier with the id 2 and the barrier with the id 4 are within 100km of each other.

By using this information and referencing the original barriers dataset we can then figure out for each barrier the segment and vertex it is located on. For example, the barrier with the id 2, is on the 56th segment, 31st vertex, and the barrier with the id 4 is on the 103rd segment, 50th vertex. We need this information to calculate the river flow direction between the two barriers. This is important as it tells us if the barrier is upstream, downstream, or not flow connected (i.e. on a different branch, i.e. for water would have to flow both up and down to reach the other barrier).

```{r}
#| label: calculate river flow direction

#create an empty list to store the output that is the same length as the input
relative_direction <- vector(mode = "list", length = nrow(distance_to_closest_barrier))

for (i in 1:nrow(distance_to_closest_barrier)){ #for each pair
  
  #pull out the unique barrier row id for each of the barriers in the pair
  start_row <- distance_to_closest_barrier[[i, 1]]
  end_row <- distance_to_closest_barrier[[i, 2]]
  
  #use the unique barrier row id to find the associated segment and vertex numbers for the barrier
  direction <- riverdirection(startseg = test_points[[start_row, 1]],
                              endseg = test_points[[end_row, 1]],
                              startvert = test_points[[start_row, 2]],
                              endvert = test_points[[end_row, 2]],
                              rivers = test_lines_clean,
                              stopiferror = F,
                              flowconnected = T)
  
  #add the resulting direction (or lack there of) to the list
  relative_direction[[i]] <- direction
  
}

#add the relative direction to our table
distance_to_closest_barrier$relative_direction <- unlist(relative_direction)

#clean up
rm(start_row, end_row, direction, relative_direction, i)

```

The resulting table: `r head(distance_to_closest_barrier, 15)`

can be mildly ambiguous as it is not 100% clear which way the barriers were measured. To clarify, we have entered barrier_a, as the starting point, and barrier_b as the ending point. So for any row that says "down" that means the water flows down from barrier_a to barrier_b. If the relative direction is NA that means the water would have to flow both down and up to reach the other barrier, i.e. the other barrier is on a separate branch of the river network.

You may also notice we have entries like this:

row1: barrier_a = 2, barrier_b = 3
row2: barrier_a = 3, barrier_b = 2

Which are essentially measuring the same thing. What we can do with is is only keep instances in which the relative direction is equal to "up" as in this case, we are only interested in barriers that have another barrier upstream. So for the above example, if row1 is "down", then row2 must be "up" and they effectively cancel each other out and we only need to keep one of them.

::: {.callout-note}
NA values are also removed as they are not flow connected.
:::

```{r}
#| label: keep only flow direction up

#filter for only relative direction is up
distance_to_closest_barrier <- distance_to_closest_barrier |> 
  filter(relative_direction == "up")

```

We also need to just keep the closest barrier, as we are not interested in the distance to all, just the distance to closest.

```{r}
#| label: keep closest only

#filter join to keep matches with the lowest distance
distance_to_closest_barrier <- distance_to_closest_barrier |> 
  group_by(barrier_a_id) |> 
  slice(which.min(distance_to_barrier)) |> 
  ungroup()

```


Now that we have the distances between each barrier, we can score them as follows:

|Value |Description |Score |
|------|------------|------|
|High  |> 100km     |100   |
|Medium|50 - 100km  |10    |
|Low   |10 - 50km   |1     |
|None  |<10km       |0     |

However in our example case, (and I'm sure in alot of cases for coastal catchments), even the largest distances are quite small - with max ranges of ~10.1km. This would just barely get a score of 1... not much of a different to a barrier that is 200m away which would get a score of 0. As an alternative, I have implemented a system in which the score is scaled from 0 to 85 based on the smallest and largest distances for each network. Scaling is done via log base 10 on the score, and then a linear scaling to fix between 0 and 85. We use the log scale to stay close to the scaling that is used in the table above, and we cap scores to 85 because distance to barrier only exists for when barriers are upstream - there is no distance when there is no barrier upstream, thus barriers in this case will get a score of 100. This means that each barrier is ranked on importance with respect to its specific system. Although this differs to the other scores that are based on importance generally, this should work well, as most of the structure of the barriers analysis is based around sequentially inspecting individual networks.

```{r}
#| label: add ranking to barriers dataset

#create the custom function
dist_to_bar_log_score <- function(x, min_val, max_val, max_score = 85) {
  
  # Handle max and min values
  if (x <= min_val) { return(0)
  } else if (x >= max_val) {return(max_score)}
  
  # Apply log10 transformation, make sure to add 1 to stop negative values and subtract the min value to not "over cook" the value
  log_transformed <- log10(x - min_val + 1)
  
  #scale the log transformed value from 0 to 100 on a linear scale
  scaled_score <- (x - min_val) / (max_val - min_val) * max_score
  
  #return the value
  return(scaled_score)

}

#apply the function to each row
distance_to_closest_barrier <- distance_to_closest_barrier |> 
  rowwise() |> 
  mutate(dist_to_bar_up_score = dist_to_bar_log_score(x = distance_to_barrier,
                                                   min_val = min(distance_to_closest_barrier$distance_to_barrier),
                                                   max_val = max(distance_to_closest_barrier$distance_to_barrier))) |> 
  ungroup()

```

And then add this score back to our original barriers dataset and fill in the blanks (NAs) for barriers that don't have anything upstream.

```{r}
#| label: add score to barrier

#strip down to the essentials
bar_upstream <- distance_to_closest_barrier |> 
  select(barrier_a_id, dist_to_bar_up_score) |> 
  mutate(barrier_a_id = as.integer(barrier_a_id))

#join to our main dataset
all_points_transformed <- left_join(all_points_transformed, bar_upstream, by = c("row_id" = "barrier_a_id"))

#for barriers that have a dist to barrier score of "NA" - these should be scored as 100
all_points_transformed <- all_points_transformed |> 
  mutate(dist_to_bar_up_score = case_when(is.na(dist_to_bar_up_score) ~ 100,
                                          T ~ dist_to_bar_up_score))

#clean up
rm(bar_upstream)

```

## Presence/Absence of downstream barrier

For this section we are interested in if there is a barrier downstream, regardless of distance, and what type of barrier it is. We will score this based on four categories:

|Value |Description                 |Score |
|------|----------------------------|------|
|High  |No barriers downstream      |100   |
|Medium|1 or more partial barriers  |10    |
|Low   |1 or more complete barriers |1     |
|None  |1 or more natural barriers  |0     |

Annoyingly, we can only really determine y/n if there is a barrier downstream. Thus, for the matrix, the only filtering we can do on the matrix is to remove distances of zero, as that is the barrier compared to itself. We can recycle the matrix that we create earlier to save time.

```{r}
#| label: filter distances

#remove instances of barriers with distance 0
barriers_downstream <- data.frame(which(distance_between_barriers > 0, arr.ind = T))

#join each of the tables together and then rename variables to help with readability
barriers_downstream <- barriers_downstream |> 
  rename(barrier_a_id = row,
         barrier_b_id = col)

#clean up
rm(distance_between_barriers)

```

We can use the resulting barrier_a_id x barrier_b_id pairs to go through and find the flow direction for each pair.

```{r}
#| label: calculate river flow direction

#create an empty list to store the output the same length as the input
relative_direction <- vector(mode = "list", length = nrow(barriers_downstream))

for (i in 1:nrow(barriers_downstream)){ #for each pair
  
  ##pull out the unique barrier row id for each of the barriers in the pair
  start_row <- barriers_downstream[[i, 1]]
  end_row <- barriers_downstream[[i, 2]]
  
  #use the unique barrier row id to find the associated segment and vertex numbers for the barrier
  direction <- riverdirection(startseg = test_points[[start_row, 1]],
                              endseg = test_points[[end_row, 1]],
                              startvert = test_points[[start_row, 2]],
                              endvert = test_points[[end_row, 2]],
                              rivers = test_lines_clean,
                              stopiferror = F,
                              flowconnected = T)
  
  #add the resulting direction (or lack there of) to the list
  relative_direction[[i]] <- direction
  
}

#add the relative direction to our table
barriers_downstream$relative_direction <- unlist(relative_direction)

#clean up
rm(start_row, end_row, direction, relative_direction, i)

```

The resulting table: `r head(barriers_downstream)`

The same logic for interpretation applies, from "a", to "b". In this table we are looking to keep only rows that contain the "down" relative direction.

```{r}
#| label: keep only flow direction up

#filter for only relative direction is down
barriers_downstream <- barriers_downstream |> 
  filter(relative_direction == "down")

```

However this dataset still contains several "downs" per barrier, as far as we are concerned, 1 barrier downstream is the same as 1000 barriers downstream. Below we filter to get only one row per barrier, not caring which one we keep.

```{r}
#| label: keep only row per barrier

#filter to only have one row per barrier
barriers_downstream <- barriers_downstream |> 
  select(-barrier_b_id) |> 
  group_by(barrier_a_id) |> 
  unique() |> 
  ungroup()

```

Finally we can add a ranking based on the table we created above, although we have a table with four possible scores we can only really give two scores (pres/abs), we will find a middle ground for scoring present. Instead of using 100 we will use 10.

```{r}
#| label: add ranking to barriers dataset

barriers_downstream <- barriers_downstream |> 
  mutate(bar_down_score = 10)

```

And then add this score to our barrier dataset and fill in the blanks (NAs) for barriers that don't have anything downstream.

```{r}
#| label: add score to barrier

#strip down to the essentials
bars_down <- barriers_downstream |> 
  select(barrier_a_id, bar_down_score)

#join to our main dataset
all_points_transformed <- left_join(all_points_transformed, bars_down, by = c("row_id" = "barrier_a_id"))

#for barriers that have a bar downstream score of "NA" - these should be scored as 100
all_points_transformed <- all_points_transformed |> 
  mutate(bar_down_score = case_when(is.na(bar_down_score) ~ 100,
                                    T ~ bar_down_score))

#clean up
rm(bars_down)

```

## Position of barrier in catchment

For this section we will calculate the position of the barrier relative to the catchment as a whole. We will score the position based on the following for categories:

|Value  |Description                                                                       |Score |
|-------|----------------------------------------------------------------------------------|------|
|High   |>80% of stream length above the barrier in relation to the total stream length.   |100   |
|Medium |50-80% of stream length above the barrier in relation to the total stream length. |10    |
|Low    |25-50% of stream length above the barrier in relation to the total stream length. |1     |
|None   |<25% of stream length above the barrier in relation to the total stream length.   |0     |

To do this, we need to figure out where the barrier sits. Although this sounds easy it is annoying to do and requires multiple steps:

- Calculate the distance from the barrier to the river mouth
- Calculate the distance from each barrier to every other segment in the network.
- Find if the path between the barrier and the segment is exclusively upstream. 
- Find the longest exclusively upstream path
- Combine the longest upstream path with the distance to the river mouth to calculate the length of the parent river.
- Find the position of the barrier along this parent river by dividing distance to mouth by total river length.

### Distance to Mouth

First is to calculate the distance from each barrier to the mouth of the river. This follows a similar method to the above sections, querying segment by segment and storing the output as a list.

```{r}
#| label: calculate lengths to mouth

#figure out the seg and vert of the mouth
mouth_seg <- test_lines_clean$mouth[[1]]
mouth_vert <- test_lines_clean$mouth[[2]]

#create an empty list to store the output, the output should have the same length as the barriers set
distance_to_mouth <- vector(mode = "list", length = nrow(test_points))

for (i in 1:nrow(test_points)){#for each segment
  
  #measure distances between each barrier
  distance <- riverdistance(startseg = test_points[[i, 1]],
                                   startvert = test_points[[i, 2]],
                                   endseg = mouth_seg,
                                   endvert = mouth_vert,
                                   rivers = test_lines_clean,
                                   stopiferror = F)
  
  #add the length to the list
  distance_to_mouth[[i]] <- distance
  
}

#convert to a vector
distance_to_mouth <- unlist(distance_to_mouth)

#add to the dataframe
test_points <- mutate(test_points, distance_to_mouth = distance_to_mouth)

#clean up
rm(mouth_seg, mouth_vert, distance, distance_to_mouth, i)

```

### Segment to Segment Distances

First we will create a matrix of distances between every segment and every other segment. This should create a matrix of ` r dim(test_lines_clean$connections)[1]` by ` r dim(test_lines_clean$connections)[1]` = ` r dim(test_lines_clean$connections)[1]* dim(test_lines_clean$connections)[1]`.

We could take this one step further and measure from every vertex within every segment, but I'm pretty sure that would blow up my computer - there are sometimes upwards of 300 vertices per segment. Instead we will just measure from the 1st vertex of each segment.

```{r}
#| label: distances between every segment

#create a vector of length 1 to n where n is the length of the number of available segments
all_segments <- 1:dim(test_lines_clean$connections)[1]

#create a vector of the same lenght as above of just 1's, this will represent the vertices
all_vertices <- rep(1, length = length(all_segments))

#measure distances between every segment, using 1 for the vertex every single time
all_distances_matrix <- riverdistancemat(seg = all_segments, 
                                         vert = all_vertices,
                                         rivers = test_lines_clean,
                                         stopiferror = F)

#clean up
rm(all_vertices)

```

### Exclusively Upstream

We will then create a matrix of water flow from each barrier to every single segment (again using 1 for the vertex).

```{r}
#| label: direction of waterflow for every segment

#create an empty dataframe to store the final output, the number of rows should equal that of one dimension of the above matrix
direction_of_flow <- data.frame(row_id = 1:dim(all_distances_matrix)[1])

#create an empty list to store the output before it goes into the dataframe, same length requirement
temporary_storage <- vector(mode = "list", length = dim(all_distances_matrix)[1])

for (i in 1:nrow(test_points)){#for each barrier in the original barriers dataset
  
  for (j in all_segments){#for every single segment that we have to check

    #check each segment by getting the water flow direction from the barrier to the segment (using 1 for the vertex)
    direction <- riverdirection(startseg = test_points[[i, 1]],
                                endseg = j,
                                startvert = test_points[[i, 2]],
                                endvert = 1,
                                rivers = test_lines_clean,
                                stopiferror = F,
                                flowconnected = T)
    
    #add the direction to a list that temporarily stores the output
    temporary_storage[[j]] <- direction
    
  }
  
  #once the list is completed (i.e. is length = matrix dim) add it as a new column in a dataframe. With col name = to segment number checked
  direction_of_flow <- direction_of_flow |> 
    mutate(!!as.character(i) := unlist(temporary_storage))
  
}

#drop the row_id col as this is useless
direction_of_flow <- select(direction_of_flow, -row_id)

#clean up
rm(temporary_storage, direction, i, j)

```

Once we have a matrix of distances between every segment and a matrix of water flow directions between the barriers and every segment we need to combine the two. First we will remove any instance in which the flow of water from the barrier to the segment is not exclusively "up" (i.e. the segment must be completely upstream of the barrier). To do this, we obtain a dataframe that gives the row and column index for each cell that contains "up".

```{r}
#| label: keep only "up"

#for each instance in the table that has an "up", use the column index to figure out which barrier and the row index to figure out which segment was "up"
where_is_up <- data.frame(which(direction_of_flow == "up", arr.ind = T))

#rename the columns to make more sense
where_is_up <- where_is_up |> 
  rename(river_segment = row,
         barrier_unique_id = col)

#clean up
rm(direction_of_flow)

```

Then we need to translate the river segment and barrier unique ids in the dataframe to match the segment number associated with the barrier and the upstream point. For example, the  river segment and barrier unique id might be 53 and 1. This means that the segment that was found to be upstream was segment 53, and the barrier was the 1st barrier (not the 1st segment). To get the segment that the barrier is on, we match the unique id of the barrier with the segment listed in the main dataframe. By doing this match (AKA left_join) we can also carry over the distance to mouth for the barrier which is useful later.

```{r}
#| label: associated barrier number to segment

#translate the column to the barrier segment
translated_segments <- left_join(where_is_up, 
                                 select(test_points, c(barrier_segment, row_id, distance_to_mouth)), 
                                 by = c("barrier_unique_id" = "row_id"))

#drop unique ID col
#translated_segments <- select(translated_segments)

#clean up
rm(where_is_up)

```

Once we know the segment number of the barrier, the segment number of any completely upstream point, and the distance from the barrier segment to the mouth. We can use these segment numbers as row and index ids to find the distance between the two segments in the distance matrix we created earlier.

```{r}
#| label: find the distance between the two segments
  
#for each of these pairs find the correct lengths by using the matrices of distances and add it as a length column
translated_segments <- translated_segments |> 
  mutate(distance_from_barseg_to_rivseg = map2_dbl(.x = translated_segments$river_segment, 
                                                   .y = translated_segments$barrier_segment, 
                                                   ~all_distances_matrix[.x, .y]))

#clean up
rm(all_distances_matrix)

```

### Longest Upstream

Below we find for each barrier the upstream point that is the furthest away.

```{r}
#| label: find longest upstream

#for each barrier (designated by the barrier column) find the longest length, and remove lengths of zero (because that is the longest distance in some cases)
longest_upstream <- translated_segments |> 
  group_by(barrier_segment) |> 
  slice(which.max(distance_from_barseg_to_rivseg)) |> 
  ungroup() |> 
  filter(distance_from_barseg_to_rivseg !=0)

```

### Total Length

And then add that distance to the distance to river mouth to find the total river length for the river that each barrier sits on and the proportion of river that the barrier blocks.

```{r}
#| label: calculate the ratio of upstream to downstream

#then for each barrier that remains, add the two distances together to get a total river distance from head to mouth
longest_upstream <- longest_upstream |> 
  rowwise() |> 
  mutate(total_river_length = sum(distance_from_barseg_to_rivseg, distance_to_mouth)) |> 
  ungroup()

#finally we can calculate a ratio of water blocked by the barrier
ratio_blocked <- longest_upstream |> 
  rowwise() |> 
  mutate(ratio_blocked = distance_from_barseg_to_rivseg/total_river_length) |> 
  ungroup()

#clean up
rm(longest_upstream)

```

Finally we can add a ranking based on the table we created above.

```{r}
#| label: add ranking to barriers dataset

#add a score per barrier distance
ratio_blocked <- ratio_blocked |> 
  mutate(bar_position_score = case_when(ratio_blocked > 0.8 ~ 100,
                                       (ratio_blocked <= 0.8 & ratio_blocked > 0.5) ~ 10,
                                       (ratio_blocked <= 0.5 & ratio_blocked > 0.25) ~ 1,
                                       ratio_blocked < 0.25 ~ 0))

```

And then add this score to our barrier dataset.

```{r}
#| label: add score to barrier

#strip down to the essentials
rat_block <- ratio_blocked |> 
  select(barrier_unique_id, bar_position_score)

#join to our main dataset
all_points_transformed <- left_join(all_points_transformed, rat_block, by = c("row_id" = "barrier_unique_id"))

#clean up
rm(rat_block)

```

## Uninterrupted Network Length Upstream

::: {.callout-note}
This metric is also discussed in detail in [issue 95](https://github.com/Northern-3/spatial-analyses/issues/95) and [issue 97](https://github.com/Northern-3/spatial-analyses/issues/97).
:::

The final metric we are going to use to score the barriers is the total length of uninterrupted stream network upstream of the barrier, this includes all tributaries and side channels, not just the main channel. This is another metric that sounds easy enough but can pose quite the challenge, mainly due to the term "uninterrupted".

Assume a river network with 1 barrier, everything above the barrier contributes to the upstream, uninterrupted network length. Now assume a river network with 2 barriers, for 1 of the barriers (the one further upstream), everything upstream of the barrier contributes to the upstream, uninterrupted network length. However for the lower barrier, the upstream, uninterrupted network length is now the network, minus the area that has been blocked off by the second barrier. This gets more complex the more barriers added.

To extend on above, assume a network with 3 barriers, all existing on and blocking the same watercourse. The highest barrier is simple, the second highest barrier can be calculated as above, however the third barrier no longer can be, because we would be double counting some areas. Thus to find the area of the lowest barrier we need to recursively check for nesting within any barriers upstream.

Thus, roughly, the devised method is as follows:

- calculate the upstream network length (regardless if interrupted or not) for all barriers
- keep on hand the segment numbers that are upstream of each barrier
- for each barriers' upstream network length, search through the segment numbers that are listed to be upstream
- if any segment number upstream of the barrier matches the segment number of another barrier note it as such
- for any barrier noted in this way, search through its' segment numbers to find any additional barriers using the same method
- repeat this until all barriers and nested barriers are found
- calculate the uninterrupted upstream network length as the original length minus the area of any barrier whos segment was noted to be upstream of the original barrier

This contained a lot of repeated words and phrases however what this actually means is just that we should treat this like a network and node question and create a network graph.

### Step 1: Find Total lengths

Below we use a table created earlier to get a dataframe of barrier - segment pairs. Where for each barrier, all of the river segments that are confirmed to be upstream of the barrier are listed. For example, barrier X, which is on the 5th river segment, has the river segments 6, 18, 39, etc, upstream of the barrier.

When then use the column that contains all of the river segments that are upstream, and pull out the segment length for each one from the original river network dataset.

```{r}
#| label: create the relationship table of each of the barriers and segments and get segment lengths

#select key variables and pull lengths from main river network dataset
river_segment_lengths <- translated_segments |> 
  select(barrier_unique_id, barrier_segment, river_segment) |> 
  mutate(length_of_river_segment = test_lines_clean$lengths[river_segment]) 

```

In the table that we just created there are rows in which the river segment upstream of the barrier is only the river segment that the barrier is on. This means that there is no additional river segments upstream of that barrier.

Following this, we can then group the data by the barrier segment and sum the river segment lengths to get the total river length that is above each barrier. An important thing we need to do here is to make sure we keep the barrier unique id as this how we connect the results back to the main dataset. However, in some case there are more than 1 barrier unique ID's per barrier segment, when this happens we will store them in a list to be extracted back out later.

```{r}
#| label: calculate total length above

#group by barrier and calculate the total river network length above each barrier
total_length <- river_segment_lengths |> 
  group_by(barrier_segment) |> 
  mutate(total_length_above_barrier = sum(unique(length_of_river_segment)),
         barrier_unique_id = list(unique(barrier_unique_id))) |> 
  ungroup() |> 
  select(-length_of_river_segment) |>
  unique()

```

### Step 2: Create a Network Graph

However this is where things get tricky. As we highlight above, we are trying to work out uninterrupted stream length, which means that the total length is sans the total length of any barrier further upstream. And this is nested logic is nested.

Above we calculated the total length for above each barrier, now we need to work out how,if, and where, each barrier is nested. To do this we need to do a network analysis. When we conduct a network analysis we can think of each barrier as a node, and the length of river upstream of the barrier as the nodes' value. To tell which nodes are connected we can look through the river_segment column (which tells us which river segments are upstream of each barrier) and keep any river segment that is also found in the barrier_segment column (which tells us which segment each barrier is on).

Thus a table that looks like this after filtering:

|Barrier Segment  |River Segment |
|-----------------|--------------|
|1                |1             |
|1                |2             |
|1                |9             |
|1                |14            |

would mean that barriers 2, 9, and 14, are all upstream of barrier 1, so the total length above barrier 1 would be the b1 length - (b2 length + b9 length + b14).

The nested part of this logic is as follows, imaging the table looked like this: 

|Barrier Segment  |River Segment |
|-----------------|--------------|
|1                |1             |
|1                |2             |
|1                |9             |
|1                |14            |
|2                |2             |
|2                |11            |

which would mean that, again, barriers 2, 9, and 14, are all upstream of barrier 1. But crucially, b11 is also further upstream of b2! Thus, the length above B1 would be:

- b2 length - b11 length = b2.0 length
- b1 length - (b2.0 length + b9 length + b14 length) = b1.0 length

Noting how the length of b2 was calculated first, then the new length of b2 was subtracted from b1.

```{r}
#| label: keep only barriers

#ensure that only barriers are nodes by keeping only river segments that contain a barrier.
total_length <- total_length |> 
  filter(river_segment %in% barrier_segment)

#we can then rename one of the columns to be more clear
total_length <- total_length |> 
  rename(barrier_upstream_of_main = river_segment)

```

That was a lot of explaining for two lines of code. lol.

Next up we need to "flatten" the barrier segment and barrier upstream segment numbers. Right now, the barrier segment numbers are directly derived from the original river segment numbers, i.e. The river segment numbers might be 1,2,3,4,5,6,7,8,9. But we only have barriers on segments 1,2 and 6, thus when looking at the columns it seems like some numbers are missing. Normally this would not be that big of a deal, but the next few steps expect nodes at every integer from min to max. If there are missing nodes, it will create new ones. Thus it will create artificial nodes at 3,4,5,7,8,9 - even though we didn't want nodes there.

Thus to avoid this, we flatten the barrier numbers.

```{r}
#| label: flatten barrier numbers

#use the dense rank function to get the order from min to max, and use this as the new barrier numbers
order_total_lengths <- total_length |> 
  mutate(barrier_rank = dense_rank(barrier_segment), 
         barrier_upstream_rank = dense_rank(barrier_upstream_of_main)) |> 
  arrange(barrier_rank)

```

Early we spoke of the value of each node being the total length of river upstream of the barrier. We need to pull this out and save it as its own named vector. This length that we pull out is the total stream length upstream of the barrier, regardless of if it is blocked.

```{r}
#| label: get original area value of each node

#get the area values
total_length_upstream <- unique(order_total_lengths$total_length_above_barrier)

#name the values so we can associate them back to the table
names(total_length_upstream) <- unique(order_total_lengths$barrier_rank)

```

We now have everything we need to create the network diagram of each of the barriers. This makes use of the igraph package and take a 2 column matrix as an input. Column one is the node (main barrier) and column two is the nodes connected to the main node (barriers upstream).

```{r}
#| label: create the network diagram

#pull out the two column and store as a matrix
edge_list <- as.matrix(select(order_total_lengths, c(barrier_rank, barrier_upstream_rank)))

#create the graph from the edge list
network_graph <- graph_from_edgelist(edge_list, directed = TRUE)

```

We can actually plot this graph, but it is so interwoven that it looks like a complete mess.

```{r}
#| label: plot just because

#plot
plot(network_graph, vertex.label = V(network_graph)$name, edge.arrow.size = 0.5, main = "Network Connections")

```

### Step 3: Calculate Uninterrupted Stream Length

So now what we have, is a list of total lengths for each node, and a graph that explains how each node is connected. The next thing we need to do is calculate the uninterrupted length. When we are calculating the length above each barrier it is very important that we calculate the length in the right order. Essentially we want to start with barriers that have nothing above them, then barriers that only have one barrier above them, then 2 barriers above them, then 3. etc.

Below we look at every node (barrier) and count the number of upstream nodes.

```{r}
#| label: count the number of upstream nodes

#create a list to store the number of upstream connections each node has
number_of_upstream_nodes <- vector(mode = "list", length = length(total_length_upstream))

#create a vector of nodes that are going to be checked
vec_of_nodes <- unique(order_total_lengths$barrier_rank)

#for each node
for (node in vec_of_nodes) {
  
  #find out the neighbors to the node that are "out" i.e. upstream
  node_neighbor <- neighbors(network_graph, node, mode = "out")
  
  #store the neighbors in a list
  number_of_upstream_nodes[[node]] <- node_neighbor

}

#name each of the items in the list, so that when we rearrange them we know which node is which
names(number_of_upstream_nodes) <- vec_of_nodes

#calculate the length of each vector in the list
number_of_upstream_nodes <- sapply(number_of_upstream_nodes, length)

```

The output of this looks like `r head(number_of_upstream_nodes)` where the top row is the barrier id, and the bottom row is the number of barriers upstream.

```{r}
#| label: order asceding 

#sort in ascending order
nodes_ascending <- sort(number_of_upstream_nodes)

```

Which looks like this: `r head(nodes_ascending)`

We can then order this named vector by number of upstream nodes in ascending order, so that barriers with the least number of upstream nodes come first. Once ordered we can swap the barrier id and the node count around so that barrier id becomes the vector value and node count becomes the vector name.

```{r}
#| label: and flip

#and flip vector name and vector value
nodes_ascending <- setNames(as.integer(names(nodes_ascending)), nodes_ascending)

```

Which looks like this: `r head(nodes_ascending)`

We can then use this vector of nodes as the order in which to calculate each nodes area. The output of which looks like this:

```{r}
#| label: update the area of each node

#create a copy called uninterrupted length to store the final output
uninterrupted_length_upstream <- total_length_upstream 
  
#for each node in the specially order vector we created
for (node in nodes_ascending){
    
  #get a list of all the upstream node neighbors
  upstream_neighbors <- neighbors(network_graph, node, mode = "out")
    
  #make sure the node length is not zero (it shouldn't be)
  if (length(upstream_neighbors) > 0){
      
    upstream_neighbors <- upstream_neighbors[upstream_neighbors != node]
      
    #update the area of the node
    uninterrupted_length_upstream[node] <- uninterrupted_length_upstream[node] - sum(uninterrupted_length_upstream[upstream_neighbors])
      
  }

}

print(head(uninterrupted_length_upstream))

```

### Step 4: Connect Back to Barriers

The final step is to connect these lengths back to the original barriers. We can do by first adding the lengths to the total lengths table using the "flattened" barrier segment numbers, and then use the original barrier segment numbers to connect back to the original dataset.

```{r}
#| label: connect back to original barriers data

#convert updated lengths to a df
uninterrupted_length_upstream <- data.frame(uninterrupted_length_upstream) |> 
  mutate(flat_bar = row_number())

#join to the main dataframe that contains the barrier ranks and segments
unin_length_up_bar_seg <- left_join(order_total_lengths, uninterrupted_length_upstream, by = c("barrier_rank" = "flat_bar"))

```

### Step 5: Scoring

We can now score, although we do need to change the units to match our scoring system.

```{r}
#| label: strip to essentials update units for scoring

#strip down to just the components need to score the length upstream
unin_length <- unin_length_up_bar_seg |> 
  select(barrier_unique_id, uninterrupted_length_upstream)

#unpack (unnest) the barrier unique_id so that when we match each unique id that was stacked gets the same length but its own row
unin_length <- unin_length |> 
  unnest(barrier_unique_id)

#remove scientific notation as it makes things hard to read quickly
options(scipen = 999)

#add units and divide by 1000 to change numbers from m to km
unin_length <- unin_length |> 
  mutate(uninterrupted_length_upstream = 
           uninterrupted_length_upstream/1000)

```

Scoring of this metric is based on the following four categories:

|Value  |Description   |Score |
|-------|--------------|------|
|High   |> 1,000km     |100   |
|Medium |500 - 1,000km |10    |
|Low    |300 - 500km   |1     |
|None   |<300km        |0     |

However in our example case, (and I'm sure in alot of cases for coastal catchments), even the barrier with the largest upstream network does not receive a score greater than 0. As an alternative to this scoring system I have implemented a system in which the score is scaled from 0 to 100 based on the smallest and largest upstream distances for each network. Scaling is done via log base 10 on the score, and then a linear scaling to fix between 0 and 100, to stay close to the scaling that is used in the table above. This means that each barrier is ranked on importance with respect to its specific system. Although this differs to the other scores that are based on importance generally, this should work well, as most of the structure of the barriers analysis is based around sequentially inspecting individual networks.

```{r}
#| label: score upstream network

#create the custom function
upstream_log_score <- function(x, min_val, max_val, max_score = 100) {
  
  # Handle max and min values
  if (x <= min_val) { return(0)
  } else if (x >= max_val) {return(max_score)}
  
  # Apply log10 transformation, make sure to add 1 to stop negative values and subtract the min value to not "over cook" the value
  log_transformed <- log10(x - min_val + 1)
  
  #scale the log transformed value from 0 to 100 on a linear scale
  scaled_score <- (x - min_val) / (max_val - min_val) * max_score
  
  #return the value
  return(scaled_score)

}

#apply the function to each row
unin_length_scored <- unin_length |> 
  rowwise() |> 
  mutate(unin_length_up_score = upstream_log_score(x = uninterrupted_length_upstream,
                                                   min_val = min(unin_length$uninterrupted_length_upstream),
                                                   max_val = max(unin_length$uninterrupted_length_upstream))) |> 
  ungroup()

#rm(unin_length)

```

We can then add these scores to the main dataset.

```{r}
#| label: add to main 

#keep only scores and id
unin_length_scored <- unin_length_scored |> 
  select(barrier_unique_id, unin_length_up_score)

all_points_transformed <- left_join(all_points_transformed, unin_length_scored, by = c("row_id" = "barrier_unique_id"))

#clean up
rm(unin_length_scored)

```

## Final Scores

All of the methods of prioritizing barriers area completed. They can now be combined to find an overall priority score for each barrier.

```{r}
#| label: final scores

all_points_transformed <- all_points_transformed |> 
  rowwise() |> 
  mutate(final_score = sum(c(dist_to_bar_up_score, bar_down_score, bar_position_score, unin_length_up_score), na.rm = T))

```

# Saving Results

The barriers have now all been allocated their scores and can be saved for visual inspection.

```{r}
#| label: save to file

st_write(all_points_transformed, glue("{save_path}/all_barriers_ranked.gpkg"))

```

# Session Info {#sec-sessioninfo}

Below is the session info at the time of rendering this script. Of greatest importance is to note the R version, and the "other attached packages" as these are the most significant drivers of success/failure. It is also good to check the "attached base packages" and "loaded via a namespace" packages as well. To check your session info use `sessionInfo()`.

```{r}
#| label: show session info

sessionInfo()

```


